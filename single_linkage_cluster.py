"""
A module for use in RepeatM. See: github.com/wwood/RepeatM

@author: Daniel Rawlinson, Australian Centre for Ecogenomics (ACE)
@email: daniel.rawlinson@uqconnect.edu.au
"""


'''
    imports
        '''

import os
import re
import subprocess
from logging import warning # also import exceptions?
import csv
import union_find_cluster



'''constants'''
#pattern to determine if contig name is in spades format
spadespattern = re.compile(r'.*NODE_[0-9]*_', re.UNICODE)

#set delimiter here?
#delim = '__'

#set sam_cmd here?

'''--------------------Begin class definition------------------------------'''
class Contig_Cluster(object):
    '''coverage and length are determined by the name of the contig produced from SPAdes. This will need to be changed if using contigs assembled with other assemblers'''
    def __init__(self, node_list, matches):
        if isinstance(node_list, str):
            raise RuntimeError('input to Contig_Cluster class must be list. String has been entered.')
        self.nodes = node_list
        self.size = len(self.nodes)
        self.av_cov = None
        self.av_length = None
        self.matches = set(matches)
         #has_spades necessary?
        if self.has_spades() == True:
            length_total = 0
            cov_total = 0
            spades_seqs = 0
            for node in self.nodes:
                if spadespattern.match(node):
                    nodeinfo = node.split('_')
                    length_total += int(nodeinfo[-3])
                    cov_total += float(nodeinfo[-1])
                    spades_seqs +=1
                else:
                    # print ("Some contigs in this cluster were not generated by Spades. Non-Spades contig names not supported yet")
                    warning('Some contigs in this cluster were not generated by Spades. Non-Spades contig names not supported yet')
            self.av_cov = int(cov_total / spades_seqs)
            self.av_length = int(length_total / spades_seqs)
        else:
            #print('Non-Spades contig names not supported yet')
            warning('Non-Spades contig names not supported yet')

    def get_rep_seq(self):
        top_len = 0
        match_nodes = [match.seqs for match in self.matches]
        for n in self.nodes:
            match_num = len([m for m in match_nodes if n in m])
            if match_num > top_len:
                top_len = match_num
                top_n = n
        return top_n

    #necessary?
    def has_spades(self):
        #check if there is at least one spades contig in node_list
        spades = False
        for c in self.nodes:
            if spadespattern.match(c):
                spades = True
                break
        return spades

    def minimal_match(self):
        '''determine lowest passing statistics from matches in cluster
        In order of: length ratio, align a > b, align b > 1, ANIm'''
        low = [1,1,1,1]
        for m in self.matches:
            stats = m.gen_statistics()
            for i in range(len(stats)):
                if stats[i] < low[i]:
                    low[i] = stats[i]

        return low


    def split_names(self):
        '''splits the names of the nodes to redraw node-assembly links in dictionary format'''
        #review 15.04.20 -- changed to nested list structure to avoid overwriting in case of identical contig names.
        #consider initialising with fixed length to save time
        node_assembly_list = []
        for n in self.nodes:
            nodesplit = n.split("__")
            node_assembly_list.append([">"+nodesplit[1], nodesplit[0]])

        return node_assembly_list


    def retrieve_seqs(self, assembly_dir, repseq = False):
        '''pull out the actual DNA sequences within the clusters from the original assemblies'''
        #all I need are nodes and location of source fasta files
        #pop out assembly number from start of contig? use as input the source fastafiles?
        #Beware leaked processes
        #can get assembly_dir from delta output?

        outdir = 'CLUSTER_size_{}_avlen_{}_avcov_{}'.format(self.size, self.av_length, self.av_cov)

        if not os.path.isdir(outdir):
            os.mkdir(outdir)

        if repseq == True:
            outfile = 'repseq_out.fa'
            assembly, node = self.get_rep_seq().split("__")
            nodes = [[">"+node, assembly]]

        else:
            outfile = 'cluster_out.fa'
            nodes = self.split_names()

        seq_out = open(outdir + "/" + outfile, 'w')

        #parallelise eventually. That's why i've written it to dictionaries first
        for link in nodes:
            node, assembly = link
            # print (node, assembly)
            f = open("/".join([assembly_dir, assembly]))
            for i in f:
                if i.find(node) != -1:
                    seq_out.write('>' + assembly + "__" + node.replace('>', '') + '\n')
                    wholeseq = False  # flag to tell me if I've taken the whole sequence yet
                    while wholeseq == False:
                        try:
                            line = next(f)
                            # print ("Found line")
                            if line.startswith('>'):
                                wholeseq = True
                            else:
                                seq_out.write(line)
                        except StopIteration:
                            # in case of last line in file
                            # print ("Stop Iteration Error")
                            wholeseq = True

        seq_out.close()

        return None




    def gen_minibam(node_assembly_dict, bam_location, outdir = 'minibam_out'): #pass self into this?
        '''Currently defunct. Plan is to use this to output a bam file for each contig in the cluster. This can be used to assess whether read mapping supports a circular or complete linear plasmid arrangement'''
        #make this automated so that python can interpret the output itself?
        #Will need to use Melody's script, plus something else I make to check for linearity'''
        sam_cmd = 'samtools view {1} {2} > %s/{1}_mini.bam' % (outdir) #edit this for correct command

        node_bam_dict = {}
        all_bams = [b for b in os.listdir(bam_location) if b.endswith('bam')]
        node_string = ''
        bam_string = ''
        for node, assembly in node_assembly_dict.items():
            bam_file = [b for b in all_bams if assembly.replace('fasta','') in b][0]
            node_bam_dict[node] = bam_file #not really necessary as I'm passing node-bam links straight into a string
            bam_string += bam_file+"\n"
            node_string += node+"\n"
            #removed input of temp_fna files
        #join into string separated by newline stuff to feed through to samtools is now in one long string with newline separators


        #TODO - load samtools and parallel into environment
        subprocess.call(['bash', '-c', 'parallel -a <(printf {}) -a <(printf {}) --link {}'.format(bam_string, node_string, sam_cmd)])

        return None
    #TODO -
    def label_cluster(self):
        ''' label cluster as linear or circular based on alignment evidence
        Evidence includes:
        - Do regions align globally or differentially? #no of matches in Nucmer_Match
        - do endings overlap?
        -are there any regions that don't match?

        -classes of alignment. Applies to each match object
            + linear
                +perfect = ends of contigs align perfectly
                +imperfect = alignment does not extend perfectly to ends
                +complex = repeats or deletions
                +simple = no repeats or deletions

            +circular
                +perfect
                +imperfect
                +complex
                +simple

Possibilites:
                            linear                |               circular
           |------------+-------------+-----------+-----------+-----------+-------
           | perfect    | imperfect   |  complex  | perfect   |imperfect  | complex
len(match) |                                      |
     1     |    *             *                   |
     2     |                  *              *    |      *           *
     3+    |                                 *    |                             *


         '''


        #selects a representative contig (the one with most matches) to test match alignment orientations
        labels = []

        repseq = self.get_rep_seq()

        #TODO - finding top_n has been moved into rep_seq function. Make sure that is connected in here to pass into label_finder
        query_matches = [m for m in self.matches if repseq in m.seqs]

        for m in query_matches:
            labels.append(m.label())

        #TODO - continue this function
        #uncovered regions
        #can only be done within each match

        #end coverage? hold one contig and check alignent stats of all others against it?
        #would be expensive to do but would give confidence as to where alignments tend to happen.


        return labels

    def has_larger(self, graph_object):
        '''check if the cluster you are looking at has a cluster of longer contigs attached to it in the cluster_graph'''
        outs = graph_object.edges[self]['out']
        if outs:
            return True
        else:
            return False


    def find_larger(self, graph_object):
        #TODO - not functioning yet
        '''find and retrieve clusters that might envelop the sequences in the given cluster'''
        return graph_object.BFS(self)

    def find_fragments(self, frag_matches): #frag_matches = list of match objects that pass fragment test (ie. align1 <0.9, align2>0.9, ani > 0.9)
        #TODO - is this in use?
        '''find fragments that constitute the same sequence but in a truncated assembly'''
        frag_elements = []
        for m in frag_matches:
            if m.seqs[0] in self.nodes or m.seqs[1] in self.nodes:
                frag_elements.append(m)

        return frag_elements


'''---------------------End class definition-------------------------------'''

def cluster_agglomerate(cluster_objs, fragment_matches):
    '''connect clusters with other similar ones. connect with fragments'''
    #TODO - pipe for cluster_graph goes here
    return

def summary_file(cluster_objs, outfile):
    '''summarise resultant clusters in a text file'''
    with open(outfile+".csv", mode="w") as f:
        writer = csv.writer(f, delimiter=",", quoting = csv.QUOTE_NONE)
        writer.writerow(['Size', 'Length', 'Coverage'])
        for c in cluster_objs:
            writer.writerow([c.size, c.av_length, c.av_cov])


def sort_clusters(cluster_list): #or maybe a dictionary instead?
    '''sort clusters by:
    1. N in cluster, 2. length of N, 3. coverage of N
    Length and coverage determined by contig names. Will need to be changed if using non-SPAdes contigs'''
    sortbysize = lambda c: (c.size is not None, c.size)
    sortbylength = lambda c: (c.av_length is not None, c.av_length)
    sortbycov = lambda c: (c.av_cov is not None, c.av_cov)


    #main sort function
    cluster_list.sort(reverse=True, key= lambda c: (sortbysize(c), sortbylength(c), sortbycov(c)))

def build_sig_match_dict(sig_matches): 
    '''to build dictionary of nodes linked to their match objects. used in cluster_nucmer_matches '''
    sig_match_dict = {}
    for m in sig_matches:

        link = m.seqs
        try:
            sig_match_dict[link[0]].append(m)
        except KeyError:
            sig_match_dict[link[0]] = [m]
        try:
            sig_match_dict[link[1]].append(m)
        except KeyError:
            sig_match_dict[link[1]] = [m]

    return sig_match_dict

def cluster_nucmer_matches(sig_matches): #sig_matches is a list of Nucmer_Match objects
    '''main clustering function. input list of nucmer match objects that pass the significance threshold (default = 0.90)'''
    cluster_objs = []

    sig_match_dict = build_sig_match_dict(sig_matches)

    cluster_list = union_find_cluster.union_find_pipe(sig_matches) #main clustering step

    for cluster in cluster_list:
        if len(cluster) >2:
            for node in cluster:
                nucmer_match_in_cluster = set(sig_match_dict[node])
            cluster_objs.append(Contig_Cluster(cluster, nucmer_match_in_cluster))

    return cluster_objs
